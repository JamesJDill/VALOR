{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c91174d",
   "metadata": {},
   "source": [
    "# VALOR Demo\n",
    "\n",
    "This notebook walks through training of VALOR on simple MuJoCo environments. It also supports rendering the contexts at the end. Run all the cells in order after installing all of the requirements inside of requirements.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c3962",
   "metadata": {},
   "source": [
    "### Imports & Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8861de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from envs import make_vec_env, ContextConcatWrapper\n",
    "from models import ActorCritic, TrajectoryDecoder\n",
    "from ppo import PPOConfig, compute_gae, ppo_update\n",
    "\n",
    "def strip_ctx(x, K):\n",
    "    return x[..., :-K]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44535882",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- training hyperparams ----\n",
    "ENV_ID = \"HalfCheetah-v5\"   # 'Hopper-v5', 'Ant-v5'\n",
    "NUM_ENVS = 16\n",
    "SEED = 1\n",
    "K = 4\n",
    "EP_LEN = 256\n",
    "TOTAL_ITERS = 300\n",
    "DECODER_STEPS = 20\n",
    "ALPHA_INT = 3.0\n",
    "ENTROPY_COEF = 0.001\n",
    "\n",
    "# plotting options\n",
    "PLOT_STATE_IDXS = (0, 1)    # which two state dims (without context) to visualize in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d64bfa",
   "metadata": {},
   "source": [
    "### Training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    env_id=ENV_ID, \n",
    "    num_envs=NUM_ENVS, \n",
    "    seed=SEED, \n",
    "    K=K, \n",
    "    ep_len=EP_LEN,\n",
    "    total_iters=TOTAL_ITERS, \n",
    "    decoder_steps=DECODER_STEPS,\n",
    "    alpha_int=ALPHA_INT, \n",
    "    entropy_coef=ENTROPY_COEF, \n",
    "    device=device\n",
    "):\n",
    "    torch.manual_seed(seed); np.random.seed(seed)\n",
    "\n",
    "    # env setup\n",
    "    vec = make_vec_env(env_id, num_envs, seed, K=K, ep_len=ep_len)\n",
    "    obs_full, infos = vec.reset(seed=seed)\n",
    "    obs_dim_full = obs_full.shape[-1]\n",
    "    obs_dim_wo = obs_dim_full - K\n",
    "    act_dim = vec.single_action_space.shape[0]\n",
    "\n",
    "    # network setup\n",
    "    net = ActorCritic(obs_dim_full, act_dim).to(device)\n",
    "    dec = TrajectoryDecoder(obs_dim_wo_ctx=obs_dim_wo, K=K).to(device)\n",
    "\n",
    "    opt = optim.Adam(net.parameters(), lr=3e-4)\n",
    "    dec_opt = optim.Adam(dec.parameters(), lr=1e-3)\n",
    "\n",
    "    cfg = PPOConfig(obs_dim=obs_dim_full, act_dim=act_dim, device=device)\n",
    "    cfg.entropy_coef = entropy_coef\n",
    "\n",
    "    # buffers\n",
    "    T, N = ep_len, num_envs\n",
    "    obs_buf = np.zeros((T, N, obs_dim_full), np.float32)\n",
    "    act_buf = np.zeros((T, N, act_dim), np.float32)\n",
    "    logp_buf = np.zeros((T, N), np.float32)\n",
    "    rew_buf = np.zeros((T, N), np.float32)\n",
    "    val_buf = np.zeros((T, N), np.float32)\n",
    "    done_buf = np.zeros((T, N), np.float32)\n",
    "\n",
    "    # context ids for this batch (from initial reset)\n",
    "    ctx_ids_for_batch = np.asarray(infos[\"context_id\"], dtype=np.int64)\n",
    "\n",
    "    # histories for logging\n",
    "    hist_iters, hist_dec_loss, hist_acc, hist_avg_int = [], [], [], []\n",
    "    last_logits = None\n",
    "    last_ctx_ids = None\n",
    "\n",
    "    for it in range(1, total_iters+1):\n",
    "        \n",
    "        # collect rollout\n",
    "        for t in range(T):\n",
    "            with torch.no_grad():\n",
    "                o = torch.as_tensor(obs_full, device=device)\n",
    "                a, logp, _ = net.sample_action(o)\n",
    "                v = net.value(o)\n",
    "\n",
    "            next_obs, r, term, trunc, infos = vec.step(a.cpu().numpy())\n",
    "            done = np.logical_or(term, trunc)\n",
    "\n",
    "            obs_buf[t] = obs_full\n",
    "            act_buf[t] = a.cpu().numpy()\n",
    "            logp_buf[t] = logp.cpu().numpy()\n",
    "            rew_buf[t] = r\n",
    "            val_buf[t] = v.cpu().numpy()\n",
    "            done_buf[t] = done.astype(np.float32)\n",
    "\n",
    "            obs_full = next_obs\n",
    "\n",
    "        # decoder batch\n",
    "        with_ctx = torch.as_tensor(obs_buf.transpose(1,0,2))\n",
    "        wo_ctx = strip_ctx(with_ctx, K).to(device)\n",
    "        ctx_ids = torch.as_tensor(ctx_ids_for_batch, dtype=torch.long, device=device)\n",
    "\n",
    "        # train decoder\n",
    "        dec.train()\n",
    "        last_dec_loss = 0.0; last_acc = 0.0\n",
    "        for _ in range(decoder_steps):\n",
    "            logits = dec(wo_ctx)\n",
    "            loss = F.cross_entropy(logits, ctx_ids)\n",
    "            dec_opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            dec_opt.step()\n",
    "            with torch.no_grad():\n",
    "                acc = (logits.argmax(-1) == ctx_ids).float().mean().item()\n",
    "                last_dec_loss = loss.item(); last_acc = acc\n",
    "\n",
    "        # intrinsic reward\n",
    "        with torch.no_grad():\n",
    "            dec.eval()\n",
    "            logits = dec(wo_ctx)\n",
    "            logp_c = F.log_softmax(logits, dim=-1).gather(1, ctx_ids.unsqueeze(1)).squeeze(1)\n",
    "            intr_ep = logp_c\n",
    "            dense = (intr_ep / T).unsqueeze(1).expand(N, T)\n",
    "            dense = (dense - dense.mean()) / (dense.std() + 1e-8)\n",
    "            r_int = dense.transpose(1,0).contiguous().to(dtype=torch.float32)\n",
    "\n",
    "        # PPO update\n",
    "        rewards_total = torch.as_tensor(rew_buf, device=device) + alpha_int * r_int.to(device)\n",
    "        adv, ret = compute_gae(\n",
    "            rewards_total.to(device),\n",
    "            torch.as_tensor(val_buf).to(device),\n",
    "            torch.as_tensor(done_buf).to(device),\n",
    "            cfg.gamma, cfg.gae_lambda\n",
    "        )\n",
    "\n",
    "        obs_flat = torch.as_tensor(obs_buf).to(device).reshape(T*N, -1)\n",
    "        act_flat = torch.as_tensor(act_buf).to(device).reshape(T*N, -1)\n",
    "        logp_flat = torch.as_tensor(logp_buf).to(device).reshape(T*N)\n",
    "        adv_flat = adv.reshape(T*N)\n",
    "        ret_flat = ret.reshape(T*N)\n",
    "\n",
    "        ppo_update(cfg, net, (obs_flat, act_flat, logp_flat, adv_flat, ret_flat), opt)\n",
    "\n",
    "        avg_int_r = rewards_total.mean().item()\n",
    "        \n",
    "        # log training metrics\n",
    "        hist_iters.append(it)\n",
    "        hist_dec_loss.append(last_dec_loss)\n",
    "        hist_acc.append(last_acc)\n",
    "        hist_avg_int.append(avg_int_r)\n",
    "\n",
    "        # log dec confusion metrics\n",
    "        last_logits = logits.detach().cpu().numpy()\n",
    "        last_ctx_ids = ctx_ids.detach().cpu().numpy()\n",
    "\n",
    "        # reset for next batch\n",
    "        obs_full, infos = vec.reset()\n",
    "        ctx_ids_for_batch = np.asarray(infos[\"context_id\"], dtype=np.int64)\n",
    "        \n",
    "        print(f\"[iter {it}/{total_iters}] dec_loss={last_dec_loss:.4f} | acc={last_acc:.3f} | avg_int_r={avg_int_r:.5f}\")\n",
    "\n",
    "    history = {\n",
    "        \"iters\": np.array(hist_iters),\n",
    "        \"dec_loss\": np.array(hist_dec_loss),\n",
    "        \"acc\": np.array(hist_acc),\n",
    "        \"avg_int\": np.array(hist_avg_int),\n",
    "        \"last_logits\": last_logits,\n",
    "        \"last_ctx_ids\": last_ctx_ids,\n",
    "        \"obs_dim_wo\": obs_dim_wo,\n",
    "    }\n",
    "    return net, dec, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net, dec, history = run_training()\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL WEIGHTS\n",
    "os.makedirs(\"weights\", exist_ok=True)\n",
    "\n",
    "# Save state_dicts (recommended for portability)\n",
    "torch.save(net.state_dict(), f\"weights/policy.pt\")\n",
    "torch.save(dec.state_dict(), f\"weights/decoder.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b4a36",
   "metadata": {},
   "source": [
    "### Decoder Loss and Accuracy graphs\n",
    "Loss should trend downwards and accuuracy should trend upwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bbc295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.figure()\n",
    "plt.plot(history[\"iters\"], history[\"dec_loss\"])\n",
    "plt.xlabel(\"Iteration\"); plt.ylabel(\"CE Loss\")\n",
    "plt.title(\"Decoder Loss\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "plt.figure()\n",
    "plt.plot(history[\"iters\"], history[\"acc\"])\n",
    "plt.xlabel(\"Iteration\"); plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Decoder Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caadc11e",
   "metadata": {},
   "source": [
    "### Final Decoder confusion matrix\n",
    "Rows = true context, Cols = predicted\n",
    "\n",
    "Should see a diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b698b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = history[\"last_logits\"]   # [N,K]\n",
    "ctx_ids = history[\"last_ctx_ids\"] # [N]\n",
    "K_current = logits.shape[1]\n",
    "\n",
    "pred = logits.argmax(axis=1)\n",
    "cm = np.zeros((K_current, K_current), dtype=int)\n",
    "for t, p in zip(ctx_ids, pred):\n",
    "    cm[t, p] += 1\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm, aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted context\")\n",
    "plt.ylabel(\"True context\")\n",
    "plt.title(\"Decoder Confusion Matrix (last batch)\")\n",
    "plt.show()\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d68f3d",
   "metadata": {},
   "source": [
    "## 7) Visualize trajectories for different contexts\n",
    "\n",
    "We roll out the trained policy in single-env mode with a **fixed** context and plot the 2D projection of two chosen state dims (just the first 2 by default). \n",
    "\n",
    "We should be able to see some visual clustering for most contexts. If there is no apparent clustering it's likely because it's happening in a different state dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_under_context(net, env_id, ctx_id, K, steps=EP_LEN):\n",
    "    env = gym.make(env_id)\n",
    "    env = ContextConcatWrapper(env, K=K, context_id=ctx_id)  # fixed context\n",
    "    obs, info = env.reset(seed=SEED)\n",
    "    obs_wo = []\n",
    "    for t in range(steps):\n",
    "        with torch.no_grad():\n",
    "            o = torch.as_tensor(obs, device=device).unsqueeze(0)\n",
    "            a, _, _ = net.sample_action(o)\n",
    "        obs, r, term, trunc, info = env.step(a.squeeze(0).cpu().numpy())\n",
    "        obs_wo.append(obs[:-K].copy())  # strip context here\n",
    "        if term or trunc:\n",
    "            break\n",
    "    return np.array(obs_wo)  # [T,D_wo]\n",
    "\n",
    "# choose dims for 2D projection\n",
    "i, j = PLOT_STATE_IDXS\n",
    "\n",
    "for ctx in range(K):\n",
    "    traj = rollout_under_context(net, ENV_ID, ctx, K, steps=EP_LEN)\n",
    "    plt.figure()\n",
    "    plt.scatter(traj[:, i], traj[:, j], s=4)\n",
    "    plt.xlabel(f\"state[{i}]\"); plt.ylabel(f\"state[{j}]\")\n",
    "    plt.title(f\"Trajectory projection for context {ctx}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def7346",
   "metadata": {},
   "source": [
    "## 8) Render Contexts\n",
    "Short rollouuts for each fixed context are rendered using the trained policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b2e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import Image as IPyImage, display\n",
    "\n",
    "CTX_COLORS = [\n",
    "    (235, 64, 52),   # red-ish\n",
    "    (52, 140, 235),  # blue-ish\n",
    "    (52, 199, 89),   # green-ish\n",
    "    (255, 159, 10),  # orange\n",
    "    (155, 89, 182),  # purple\n",
    "    (46, 204, 113),  # emerald\n",
    "    (241, 196, 15),  # sunflower\n",
    "    (26, 188, 156),  # teal\n",
    "]\n",
    "\n",
    "def make_rgb_env(env_id, K, ctx_id, seed=1):\n",
    "    env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "    env = ContextConcatWrapper(env, K=K, context_id=ctx_id)\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    return env, obs\n",
    "\n",
    "def _frame_with_border_and_text(frame, ctx_id, step, K, border_px=6):\n",
    "    h, w, _ = frame.shape\n",
    "    color = CTX_COLORS[ctx_id % len(CTX_COLORS)]\n",
    "    \n",
    "    canvas = np.zeros((h + 2*border_px, w + 2*border_px, 3), dtype=np.uint8)\n",
    "    canvas[:] = color\n",
    "    canvas[border_px:border_px+h, border_px:border_px+w] = frame\n",
    "\n",
    "    # add text\n",
    "    pil_img = Image.fromarray(canvas)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    \n",
    "    txt = f\"ctx={ctx_id} / K={K} | step={step}\"\n",
    "    try:\n",
    "        tw = draw.textlength(txt)\n",
    "    except Exception:\n",
    "        tw = 8 * len(txt)\n",
    "        \n",
    "    th = 12\n",
    "    draw.rectangle([8, 8, 8 + int(tw) + 8, 8 + th + 8], fill=(0,0,0,160))\n",
    "    draw.text((12, 12), txt, fill=(255,255,255))\n",
    "    return np.array(pil_img)\n",
    "\n",
    "def rollout_gif(net, env_id, K, ctx_id, steps=300, fps=30, seed=1, out_dir=\"videos\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    env, obs = make_rgb_env(env_id, K, ctx_id, seed=seed)\n",
    "    frames = []\n",
    "    \n",
    "    for t in range(steps):\n",
    "        with torch.no_grad():\n",
    "            o = torch.as_tensor(obs, device=device).unsqueeze(0)\n",
    "            a, _, _ = net.sample_action(o)\n",
    "            \n",
    "        obs, r, term, trunc, info = env.step(a.squeeze(0).cpu().numpy())\n",
    "        \n",
    "        frame = env.render()\n",
    "        if frame is None:\n",
    "            break\n",
    "        \n",
    "        frame = _frame_with_border_and_text(frame, ctx_id, t, K)\n",
    "        frames.append(frame)\n",
    "        \n",
    "        if term or trunc:\n",
    "            break\n",
    "        \n",
    "    env.close()\n",
    "    if not frames:\n",
    "        return None\n",
    "    \n",
    "    path = os.path.join(out_dir, f\"{env_id}_ctx{ctx_id}.gif\")\n",
    "    imageio.mimsave(path, frames, fps=fps, loop=0)\n",
    "    return path\n",
    "\n",
    "def show_context_videos(net, env_id, K, steps=300, fps=30, seed=1):\n",
    "    paths = []\n",
    "\n",
    "    for ctx in range(K):\n",
    "        p = rollout_gif(net, env_id, K, ctx, steps=steps, fps=fps, seed=seed)\n",
    "        paths.append(p)\n",
    "        \n",
    "    for p in paths:\n",
    "        if p is not None:\n",
    "            display(IPyImage(filename=p))\n",
    "        else:\n",
    "            print(\"No frames for one of the contexts (render returned None).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b5659",
   "metadata": {},
   "source": [
    "You should see gifs for each context appear in videos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb23cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_context_videos(net, ENV_ID, K, steps=128, fps=10, seed=SEED) # This might take a couuple minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
